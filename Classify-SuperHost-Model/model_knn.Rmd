---
title: "Model_KNN"
author: "Nam Tran"
date: "4/12/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr); library(tidyverse); library(dplyr); library(psych); library(PerformanceAnalytics); library(skimr); library(lessR); library(ggplot2); library(gridExtra); library(fastDummies); library(forecast); library(BMA); library(stats); library(olsrr); library(MASS); library(kableExtra); library(car); library(broom); library(glmulti); library(ggmap); library(rstudioapi); library(revgeo); library(RCurl);library(stringr); library(gsubfn);library(ngram);library(stringr); library(tm); library(caret); library(class)
```


```{r}
df <- read.csv("Airbnb_DataCleaning3.csv.csv")
```

```{r}
str(df)
```

```{r}
num_val <- c("host.response.rate", "host.acceptance.rate", "host.total.listings.count", "accommodates", "bedrooms", "beds", "price", "number.of.reviews",
             "number.of.reviews.ltm", "review.scores.rating", "review.scores.accuracy", "review.scores.cleanliness", "review.scores.checkin", "review.scores.communication",
             "review.scores.location", "review.scores.value", "reviews.per.month", "amenities.count", "Med.Area.House.Value","Percen.Under.Poverty")
cate_val <- c("host.response.time", "host.is.superhost", "host.has.profile.pic", "host.identity.verified", "room.type", "instant.bookable",
              "Density.Bin","Bathroom.Type")
dummy_val <- c("air.conditioning", "high.end.electronics", "bbq", "balcony", "breakfast", "tv", "coffee.machine", "kitchen", "white.goods", "gym", "parking", 
               "outdoor.space", "hottub.sauna.pool", "internet", "long.term.Stay.allowed", "private.entrance", "secure")
length(num_val)
length(cate_val)
length(dummy_val)
```



### Create Dummy Variables for Categorical Variables
```{r}
df <- fastDummies::dummy_cols(df, select_columns = cate_val, remove_first_dummy = TRUE)
```

```{r}
Unselect_val <- c("X", "host.id", "name", "description", "neighborhood.overview", "neighbourhood.cleansed", "neighbourhood.group.cleansed",
                  "City", "State", "Zip","bathrooms.text" ,cate_val)
model_df <- df[,!colnames(df) %in% Unselect_val]
model_df
```

### Interaction of Price and Room type
```{r}
model_df$PriceXhotelType <- model_df$price*model_df$`room.type_Hotel room`
model_df$PriceXprivateType <- model_df$price*model_df$`room.type_Private room`
model_df$PriceXsharedType <- model_df$price*model_df$`room.type_Shared room`

```

### NORMALIZE NUMERICAL VARIABLE

```{r}
model_df[,num_val] <- scale(model_df[,num_val])
```

```{r}
model_df <- model_df[!is.na(model_df$Med.Area.House.Value),]
model_df <- model_df[!is.na(model_df$Percen.Under.Poverty),]
as.data.frame(colSums(is.na(model_df)))
dim(model_df)
```

```{r}
Unselect_val <- c("X", "host.id", "name", "description", "neighborhood.overview", "neighbourhood.cleansed", "neighbourhood.group.cleansed",
                  "City", "State", "Zip","bathrooms.text" ,cate_val, "beds", "review.scores.accuracy", "review.scores.cleanliness", "review.scores.checkin",
                  "review.scores.communication", "reviews.per.month", "number.of.reviews")
model_df <- model_df[,!colnames(model_df) %in% Unselect_val]
```

### PATITION DATA: 70% of TRAIN DATA, 30% of TEST DATA
```{r}
set.seed(1)

## partitioning into training (70%), validation (30%)
#train.index <- sample(rownames(model_df), dim(model_df)[1]*0.7)  # randomly sample 70% of the row IDs for training
#valid.index <- setdiff(rownames(model_df), train.index)           # use setdiff() to find records not already in the training set

# create the 2 data frames by collecting all columns from the appropriate rows
#train.df <- model_df[train.index, ]
#valid.df <- model_df[valid.index, ]

```

```{r}
## Randomly partition the data into 25% testing data and the remaining 75% data.
test_rowname = sample(nrow(model_df), 0.25*nrow(model_df))
df_knn_test <- model_df[test_rowname,]
## Save the rest of the data as the data that isn't testing
df_knn_rest <- model_df[-test_rowname,]
## e. Randomly partition the remaining data into 70% training data and 30% validation data.
valid_rowname = sample(nrow(df_knn_rest), 0.3*nrow(df_knn_rest))
df_knn_valid <- df_knn_rest[valid_rowname,]
df_knn_train <- df_knn_rest[-valid_rowname,]
#View(df_competition)

train.Y <- df_knn_train[,42]
valid.Y <- df_knn_valid[,42]
```

```{r}
head(df_knn_train)
```


```{r}
colnames(df_knn_train)

```


```{r}
train.X=df_knn_train[,-42]
valid.X=df_knn_valid[,-42]
test.X=df_knn_test[,-42]
```

```{r}
dim(train.X)
dim(train.Y)
```

```{r}
knn.pred_tr=knn(train.X,train.X,train.Y,k=1)
knn.pred_va=knn(train.X,valid.X,train.Y,k=1)

grid_knn = c(1, 3, 5, 7, 9,11, 13,15,17, 19)

vals<- matrix(NA,nrow=10,ncol=3)
ind<-1
#Following function will take a lot of time
#calculate training and calidation accuracies for each k value in grid_knn
for (kval in grid_knn){ #for each value in the grid
  
  
  knn.pred_va=knn(train.X,valid.X,train.Y,k=kval)
  knn.pred_tr=knn(train.X,train.X,train.Y,k=kval)
  
  
  #Computing the accuracy on validation and training
  correct_va <- sum(ifelse(knn.pred_va==valid.Y,1,0))
  accuracy_va <- (1.0*correct_va)/nrow(valid.X)
  correct_tr <- sum(ifelse(knn.pred_tr==train.Y,1,0))
  accuracy_tr <- (1.0*correct_tr)/nrow(train.X)
  
  vals[ind,1] <- kval
  vals[ind,2] <- accuracy_va
  vals[ind,3] <- accuracy_tr
  
  ind <-ind+1
}

#View our matrix
vals  

# plotting the training and validation accuracies
plot(vals[,1],vals[,2],type='l',col='red',xlab = "Value of k",ylab = "Accuracy",ylim=c(0,1))
lines(vals[,1],vals[,3],col='dark blue')
#We see that the best model is  at k = ?

```


```{r}
test.Y=df_knn_test[,42]
knn.pred <- knn(train.X, test.X, cl = train.Y, k = 3) 
confusionMatrix(as.factor(knn.pred), as.factor(test.Y), ,positive = "1")
```



